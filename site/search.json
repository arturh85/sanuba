{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Sunaba: Emergent Artificial Life","text":"<p>Sunaba is a research-oriented sandbox exploring the intersection of emergent physics simulation and evolutionary artificial life. This documentation provides scientific context for the algorithms and techniques employed.</p> <p></p>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#play-the-game","level":2,"title":"Play the Game","text":"<p>The playable web version is available at /game/.</p>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#visual-showcase","level":2,"title":"Visual Showcase","text":"","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#emergent-physics","level":3,"title":"Emergent Physics","text":"Fire spreading through wooden structures  <p>Fire propagates through flammable materials based on temperature and material properties</p>    Water flowing down platforms  <p>Liquids flow with realistic viscosity and density interactions</p>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#structural-integrity","level":3,"title":"Structural Integrity","text":"Bridge collapse with cascade failure  <p>Structures collapse when support is removed, demonstrating emergent structural dependencies</p>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#material-diversity","level":3,"title":"Material Diversity","text":"<p> 37 unique materials with distinct properties and interactions</p> <p> Extended material system: ores, organics, refined materials, and special compounds</p>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#chemistry-reactions","level":3,"title":"Chemistry &amp; Reactions","text":"Lava meets water reaction  <p>Temperature-based state changes: lava + water → steam + stone</p>    Multiple material reactions  <p>Comprehensive chemistry: gunpowder explosions, acid corrosion, organic transformations</p>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#advanced-systems","level":3,"title":"Advanced Systems","text":"Plant growth under light  <p>Light propagation and organic growth systems enable renewable resources</p> <p> Day/night cycle with realistic light propagation from multiple sources</p>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#user-interface","level":3,"title":"User Interface","text":"<p> Inventory management with item stacking and tool durability</p> <p> Recipe-based crafting for material transformations</p>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#the-core-question","level":2,"title":"The Core Question","text":"<p>Can complex, adaptive behaviors emerge from the interaction of simple rules and evolutionary pressure?</p> <p>This question has driven artificial life research since the field's start. Sunaba approaches it by combining two powerful paradigms:</p> <ol> <li>Pixel-based physics simulation — where material behaviors emerge from cellular automata rules rather than hand-coded interactions</li> <li>Neuroevolution — where creature morphologies and neural controllers co-evolve to survive in this emergent world</li> </ol>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#why-emergence-matters","level":2,"title":"Why Emergence Matters","text":"<p>Traditional game AI relies on explicitly programmed behaviors. A creature \"knows\" to hunt because a designer wrote hunting code. In contrast, emergent systems produce behaviors that were never explicitly programmed.</p> <p>Consider fire spreading through a forest. In Sunaba: - Wood has a property: <code>flammability</code> - Fire has a property: <code>heat_output</code> - A reaction rule exists: \"if wood temperature exceeds ignition point, convert to fire\"</p> <p>No one programmed \"forest fires.\" The behavior emerges from simple rules interacting.</p> <p>The same principle applies to creatures. Their behaviors emerge from: - Morphology generated by CPPN-NEAT - Neural controllers evolved through MAP-Elites - Selection pressure from the simulated environment</p>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#documentation-overview","level":2,"title":"Documentation Overview","text":"Section Focus Emergent Physics Cellular automata and falling sand simulation CPPN-NEAT Procedural morphology generation MAP-Elites Quality-diversity evolutionary optimization Neural Control Brain architectures for embodied agents Prior Work Literature review and inspirations Architecture System design with diagrams","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#key-algorithms-at-a-glance","level":2,"title":"Key Algorithms at a Glance","text":"<pre><code>flowchart LR\n    subgraph Evolution\n        G[CPPN Genome] --&gt; M[Morphology]\n        M --&gt; N[Neural Controller]\n        N --&gt; B[Behavior]\n        B --&gt; F[Fitness]\n        F --&gt; S[Selection]\n        S --&gt; G\n    end\n\n    subgraph World\n        CA[Cellular Automata] --&gt; Physics\n        Physics --&gt; Sensors\n        Sensors --&gt; N\n    end</code></pre>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"#references","level":2,"title":"References","text":"<p>This project builds on decades of research in artificial life, neuroevolution, and emergent simulation. Key influences include:</p> <ul> <li>Stanley, K.O. (2007). Compositional Pattern Producing Networks</li> <li>Mouret, J.-B. &amp; Clune, J. (2015). Illuminating search spaces by mapping elites</li> <li>Sims, K. (1994). Evolved Virtual Creatures</li> <li>Nolla Games (2019). Noita — Falling sand physics</li> </ul> <p>See Prior Work for a comprehensive literature review.</p>","path":["Sunaba: Emergent Artificial Life"],"tags":[]},{"location":"architecture/","level":1,"title":"Architecture: System Design","text":"<p>This page provides technical diagrams showing how Sunaba's systems fit together. For code-level details, see the repository's CLAUDE.md file.</p>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#high-level-system-overview","level":2,"title":"High-Level System Overview","text":"<pre><code>flowchart TB\n    subgraph \"Game Layer\"\n        UI[User Interface]\n        R[Renderer]\n        Input[Input Handler]\n    end\n\n    subgraph \"Simulation Core\"\n        W[World Manager]\n        CA[Cellular Automata Engine]\n        T[Temperature System]\n        S[Structural Integrity]\n        P[Physics Engine]\n    end\n\n    subgraph \"Creature System\"\n        C[Creature Manager]\n        B[Brain/Neural Controller]\n        G[GOAP Planner]\n        Sensors[Sensor System]\n    end\n\n    subgraph \"Evolution Pipeline\"\n        ME[MAP-Elites Archive]\n        CPPN[CPPN-NEAT Generator]\n        Eval[Fitness Evaluation]\n    end\n\n    Input --&gt; W\n    W --&gt; CA\n    W --&gt; T\n    W --&gt; S\n    W --&gt; P\n    CA --&gt; R\n    P --&gt; C\n    Sensors --&gt; B\n    B --&gt; C\n    C --&gt; W\n    CPPN --&gt; C\n    Eval --&gt; ME\n    ME --&gt; CPPN</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#simulation-layers","level":2,"title":"Simulation Layers","text":"<p>The world simulation operates in layers with different update frequencies:</p> <pre><code>flowchart TD\n    subgraph \"60 FPS\"\n        CA[Cellular Automata]\n        Physics[Rigid Body Physics]\n        Neural[Neural Inference]\n    end\n\n    subgraph \"30 FPS\"\n        Temp[Temperature Diffusion]\n        GOAP[GOAP Planning]\n    end\n\n    subgraph \"Event-Driven\"\n        Struct[Structural Integrity]\n        React[Chemical Reactions]\n    end\n\n    CA --&gt; Temp\n    CA --&gt; Struct\n    Physics --&gt; Neural\n    Neural --&gt; GOAP</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#layer-interaction","level":3,"title":"Layer Interaction","text":"<pre><code>sequenceDiagram\n    participant CA as Cellular Automata\n    participant Temp as Temperature\n    participant Struct as Structural\n    participant Phys as Physics\n\n    loop Every Frame\n        CA-&gt;&gt;CA: Update pixel positions\n        CA-&gt;&gt;Temp: Report heat sources\n        Temp-&gt;&gt;Temp: Diffuse heat (every 2nd frame)\n        Temp-&gt;&gt;CA: Trigger state changes\n        CA-&gt;&gt;Struct: Report removals\n        Struct-&gt;&gt;Phys: Create debris bodies\n        Phys-&gt;&gt;CA: Update body positions\n    end</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#world-structure","level":2,"title":"World Structure","text":"","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#chunk-organization","level":3,"title":"Chunk Organization","text":"<pre><code>flowchart LR\n    subgraph \"World\"\n        direction TB\n        subgraph \"Active Chunks\"\n            A1[Chunk 0,0]\n            A2[Chunk 1,0]\n            A3[Chunk 0,1]\n            A4[Chunk 1,1]\n        end\n\n        subgraph \"Loaded Chunks\"\n            L1[Chunk -1,0]\n            L2[Chunk 2,0]\n        end\n\n        subgraph \"Disk\"\n            D1[Serialized chunks...]\n        end\n    end\n\n    A1 &lt;--&gt; A2\n    A2 &lt;--&gt; A4\n    A1 &lt;--&gt; A3\n    A3 &lt;--&gt; A4\n    L1 &lt;--&gt; A1\n    L2 &lt;--&gt; A2\n    D1 -.-&gt; L1\n    D1 -.-&gt; L2</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#chunk-data-layout","level":3,"title":"Chunk Data Layout","text":"<pre><code>Chunk (64×64 pixels)\n├── pixel_data: [u32; 4096]\n│   ├── bits 0-15:  material_id\n│   ├── bits 16-23: flags\n│   └── bits 24-31: variant/metadata\n├── temperature: [f32; 64]  (8×8 coarse grid)\n├── light: [u8; 4096]\n└── dirty_rect: Option&lt;Rect&gt;\n</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#evolution-pipeline","level":2,"title":"Evolution Pipeline","text":"","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#offline-training-flow","level":3,"title":"Offline Training Flow","text":"<pre><code>flowchart TD\n    subgraph \"Initialization\"\n        I1[Create random CPPN genomes]\n        I2[Initialize MAP-Elites archive]\n    end\n\n    subgraph \"Evolution Loop\"\n        S1[Select from archive]\n        S2[Mutate genome]\n        S3[Build morphology from CPPN]\n        S4[Initialize neural controller]\n        S5[Run evaluation scenario]\n        S6[Compute fitness + behavior]\n        S7[Update archive]\n    end\n\n    I1 --&gt; I2\n    I2 --&gt; S1\n    S1 --&gt; S2\n    S2 --&gt; S3\n    S3 --&gt; S4\n    S4 --&gt; S5\n    S5 --&gt; S6\n    S6 --&gt; S7\n    S7 --&gt; S1</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#cppn-morphology-generation","level":3,"title":"CPPN Morphology Generation","text":"<pre><code>flowchart TD\n    subgraph \"CPPN Query\"\n        Q1[Define bounding box]\n        Q2[Generate query points]\n        Q3[For each point x,y,d]\n        Q4[Feed into CPPN network]\n        Q5[Get outputs]\n    end\n\n    subgraph \"Body Construction\"\n        B1{presence &gt; threshold?}\n        B2[Create segment]\n        B3[Assign to body graph]\n        B4[Determine joint type]\n        B5[Connect to neighbors]\n    end\n\n    Q1 --&gt; Q2 --&gt; Q3 --&gt; Q4 --&gt; Q5\n    Q5 --&gt; B1\n    B1 --&gt;|Yes| B2\n    B2 --&gt; B3 --&gt; B4 --&gt; B5\n    B1 --&gt;|No| Q3\n    B5 --&gt; Q3</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#creature-lifecycle","level":2,"title":"Creature Lifecycle","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Spawning: CPPN generates body\n\n    Spawning --&gt; Active: Body valid\n\n    state Active {\n        [*] --&gt; Sensing\n        Sensing --&gt; Thinking: Sensor data collected\n        Thinking --&gt; Acting: Motor commands generated\n        Acting --&gt; Sensing: Physics stepped\n    }\n\n    Active --&gt; Dead: Health &lt;= 0\n    Active --&gt; Dead: Fall out of world\n    Active --&gt; Reproducing: Fitness threshold\n\n    Reproducing --&gt; Active: Offspring spawned\n\n    Dead --&gt; [*]: Despawn</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#neural-control-pipeline","level":2,"title":"Neural Control Pipeline","text":"","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#per-frame-processing","level":3,"title":"Per-Frame Processing","text":"<pre><code>flowchart LR\n    subgraph \"Sensors\"\n        P[Proprioception]\n        E[Exteroception]\n        I[Internal State]\n    end\n\n    subgraph \"Encoding\"\n        PE[Prop Encoder]\n        EE[Ext Encoder]\n        IE[State Encoder]\n    end\n\n    subgraph \"Brain\"\n        H1[Hidden 64]\n        H2[Hidden 64]\n        H3[Hidden 32]\n        O[Output]\n    end\n\n    subgraph \"Motors\"\n        M1[Joint 1]\n        M2[Joint 2]\n        M3[Joint N]\n    end\n\n    P --&gt; PE --&gt; H1\n    E --&gt; EE --&gt; H1\n    I --&gt; IE --&gt; H1\n    H1 --&gt; H2 --&gt; H3 --&gt; O\n    O --&gt; M1\n    O --&gt; M2\n    O --&gt; M3</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#sensor-details","level":3,"title":"Sensor Details","text":"<pre><code>flowchart TD\n    subgraph \"Proprioception per Joint\"\n        J1[angle: -π to π]\n        J2[velocity: normalized]\n        J3[torque: normalized]\n        J4[contact: 0 or 1]\n    end\n\n    subgraph \"Exteroception\"\n        R1[8 raycasts × 3 values]\n        R2[distance, material, temperature]\n    end\n\n    subgraph \"Internal State\"\n        S1[health: 0 to 1]\n        S2[hunger: 0 to 1]\n        S3[orientation: sin, cos]\n    end</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#training-scenarios","level":2,"title":"Training Scenarios","text":"","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#scenario-types","level":3,"title":"Scenario Types","text":"<pre><code>flowchart LR\n    subgraph \"Locomotion\"\n        L1[Flat terrain]\n        L2[Target point reward]\n        L3[Time limit: 30s]\n    end\n\n    subgraph \"Foraging\"\n        F1[Scattered food]\n        F2[Consumption reward]\n        F3[Time limit: 60s]\n    end\n\n    subgraph \"Survival\"\n        S1[Hazards present]\n        S2[Food + threats]\n        S3[Time limit: 120s]\n    end\n\n    subgraph \"Combat\"\n        C1[Opponent creature]\n        C2[Damage dealt reward]\n        C3[Time limit: 60s]\n    end</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#fitness-computation","level":3,"title":"Fitness Computation","text":"<pre><code>flowchart TD\n    subgraph \"Raw Metrics\"\n        M1[distance_traveled]\n        M2[food_eaten]\n        M3[time_survived]\n        M4[damage_dealt]\n        M5[offspring_produced]\n    end\n\n    subgraph \"Weights\"\n        W1[scenario-specific weights]\n    end\n\n    subgraph \"Final Fitness\"\n        F[weighted sum]\n    end\n\n    M1 --&gt; W1\n    M2 --&gt; W1\n    M3 --&gt; W1\n    M4 --&gt; W1\n    M5 --&gt; W1\n    W1 --&gt; F</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#map-elites-archive","level":2,"title":"MAP-Elites Archive","text":"","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#archive-structure","level":3,"title":"Archive Structure","text":"<pre><code>flowchart TD\n    subgraph \"2D Behavior Space\"\n        direction LR\n        subgraph \"Axis 1: Ground Contact\"\n            X1[0.0]\n            X2[0.25]\n            X3[0.5]\n            X4[0.75]\n            X5[1.0]\n        end\n    end\n\n    subgraph \"Archive Grid\"\n        G[20 × 20 cells]\n        E[Each cell: elite genome + fitness]\n    end\n\n    X1 --&gt; G\n    X5 --&gt; G</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#archive-operations","level":3,"title":"Archive Operations","text":"<pre><code>sequenceDiagram\n    participant E as Evaluator\n    participant A as Archive\n    participant S as Selector\n\n    E-&gt;&gt;E: Evaluate creature\n    E-&gt;&gt;E: Compute behavior descriptor\n    E-&gt;&gt;A: Check cell for behavior\n    alt Cell empty\n        A-&gt;&gt;A: Store genome + fitness\n    else Cell occupied\n        alt New fitness &gt; stored fitness\n            A-&gt;&gt;A: Replace with new\n        else\n            A-&gt;&gt;A: Discard new\n        end\n    end\n    S-&gt;&gt;A: Request random elite\n    A-&gt;&gt;S: Return genome for mutation</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#data-flow-summary","level":2,"title":"Data Flow Summary","text":"<pre><code>flowchart TB\n    subgraph \"Genotype\"\n        CPPN_G[CPPN Genome]\n        NN_G[Neural Weights]\n    end\n\n    subgraph \"Phenotype\"\n        Body[Physical Body]\n        Brain[Neural Controller]\n    end\n\n    subgraph \"Behavior\"\n        Actions[Motor Commands]\n        Interact[World Interactions]\n    end\n\n    subgraph \"Evaluation\"\n        Metrics[Performance Metrics]\n        BC[Behavior Characterization]\n        Fit[Fitness Score]\n    end\n\n    subgraph \"Selection\"\n        Archive[MAP-Elites Archive]\n        Mutation[Mutation Operators]\n    end\n\n    CPPN_G --&gt; Body\n    NN_G --&gt; Brain\n    Body --&gt; Actions\n    Brain --&gt; Actions\n    Actions --&gt; Interact\n    Interact --&gt; Metrics\n    Metrics --&gt; BC\n    Metrics --&gt; Fit\n    BC --&gt; Archive\n    Fit --&gt; Archive\n    Archive --&gt; Mutation\n    Mutation --&gt; CPPN_G\n    Mutation --&gt; NN_G</code></pre>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#user-interface","level":2,"title":"User Interface","text":"<p>Sunaba's UI is built with egui, providing immediate-mode rendering for game controls and information displays.</p>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#inventory-system","level":3,"title":"Inventory System","text":"<p>The inventory system supports: - Item Stacking: Materials stack up to 999 per slot - Tool Durability: Tools show remaining uses and degrade with use - Quick Access: Hotbar for frequently used items - Visual Feedback: Item icons with quantity displays</p>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#crafting-system","level":3,"title":"Crafting System","text":"<p>The crafting interface provides: - Recipe Discovery: Available recipes shown based on inventory - Material Requirements: Clear display of required ingredients - Output Preview: Shows crafted item before creation - Batch Crafting: Support for creating multiple items at once</p>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#material-showcase","level":3,"title":"Material Showcase","text":"<p> Basic material showcase: 8 fundamental materials with distinct visual properties</p> <p> Phase 5 materials: 30+ materials including ores, organics, refined materials, and special compounds</p>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#lighting-world-systems","level":3,"title":"Lighting &amp; World Systems","text":"<p> Light propagation demonstration: underground lava, fire sources, and surface daylight</p>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#structural-complexity","level":3,"title":"Structural Complexity","text":"<p> Complex architectural structures demonstrating building capabilities</p> <p> Tutorial level with resource distribution and starter area</p>","path":["Architecture: System Design"],"tags":[]},{"location":"architecture/#tech-stack-summary","level":2,"title":"Tech Stack Summary","text":"Component Technology Language Rust Graphics wgpu UI egui Windowing winit Physics rapier2d Math glam Serialization serde + bincode Compression lz4_flex RNG rand + rand_xoshiro Graphs petgraph","path":["Architecture: System Design"],"tags":[]},{"location":"cppn-neat/","level":1,"title":"CPPN-NEAT: Procedural Morphology Generation","text":"<p>Sunaba's creatures don't have hand-designed bodies. Instead, their morphologies are procedurally generated by Compositional Pattern Producing Networks (CPPNs), evolved using NeuroEvolution of Augmenting Topologies (NEAT).</p>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#the-problem-designing-bodies","level":2,"title":"The Problem: Designing Bodies","text":"<p>How do you create diverse, functional creature morphologies without hand-designing each one?</p> <p>Nature's solution is development — a genetic blueprint (genotype) unfolds into a physical body (phenotype) through growth processes. The same approach can work for artificial creatures.</p>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#compositional-pattern-producing-networks-cppns","level":2,"title":"Compositional Pattern Producing Networks (CPPNs)","text":"","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#what-is-a-cppn","level":3,"title":"What is a CPPN?","text":"<p>A CPPN is a neural network that generates patterns by taking spatial coordinates as input and outputting values that determine properties at those locations.</p> <pre><code>flowchart LR\n    subgraph Inputs\n        X[x coordinate]\n        Y[y coordinate]\n        D[distance from center]\n    end\n\n    subgraph \"CPPN Network\"\n        H1[Hidden Layer]\n        H2[Hidden Layer]\n    end\n\n    subgraph Outputs\n        M[Material presence]\n        J[Joint type]\n        S[Segment ID]\n    end\n\n    X --&gt; H1\n    Y --&gt; H1\n    D --&gt; H1\n    H1 --&gt; H2\n    H2 --&gt; M\n    H2 --&gt; J\n    H2 --&gt; S</code></pre>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#why-cppns-work","level":3,"title":"Why CPPNs Work","text":"<p>CPPNs leverage geometric regularities found in natural organisms:</p> Regularity Activation Function Effect Symmetry Gaussian (distance) Bilateral symmetry Repetition Sine Repeating segments Gradients Linear Smooth transitions Sharp boundaries Step Distinct regions <p>By combining these functions, CPPNs can produce: - Bilaterally symmetric bodies - Repeating limb segments - Smooth body contours - Distinct organs/regions</p>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#activation-functions","level":3,"title":"Activation Functions","text":"<p>CPPNs use diverse activation functions, each contributing different geometric properties:</p> <pre><code>flowchart TB\n    subgraph \"Activation Functions\"\n        direction LR\n        A1[\"sin(x): Repetition\"]\n        A2[\"gauss(x): Symmetry\"]\n        A3[\"sigmoid(x): Gradients\"]\n        A4[\"step(x): Boundaries\"]\n        A5[\"abs(x): V-shapes\"]\n    end</code></pre> <p>Sine — Creates repeating, periodic patterns (limb segments, stripes)</p> <p>Gaussian — Creates radially symmetric patterns (eyes, body centers)</p> <p>Sigmoid — Creates smooth gradients (density variations, tapers)</p> <p>Step — Creates sharp boundaries (distinct body regions)</p> <p>Absolute value — Creates V-shaped patterns (limb bifurcations)</p>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#cppn-query-process","level":3,"title":"CPPN Query Process","text":"<p>To generate a creature body, we query the CPPN at many spatial coordinates:</p> <pre><code>flowchart TD\n    A[Define query grid] --&gt; B[For each point x,y]\n    B --&gt; C[Compute distance d from origin]\n    C --&gt; D[Feed x,y,d into CPPN]\n    D --&gt; E[Get output values]\n    E --&gt; F{material_presence &gt; threshold?}\n    F --&gt;|Yes| G[Create body segment]\n    F --&gt;|No| H[Empty space]\n    G --&gt; I[Assign joint type from output]\n    I --&gt; B</code></pre>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#neat-neuroevolution-of-augmenting-topologies","level":2,"title":"NEAT: NeuroEvolution of Augmenting Topologies","text":"","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#the-challenge-of-evolving-network-topology","level":3,"title":"The Challenge of Evolving Network Topology","text":"<p>Traditional neuroevolution fixes the network architecture and only evolves weights. But optimal topology varies by problem. NEAT solves this by evolving both topology and weights simultaneously.</p>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#historical-markings","level":3,"title":"Historical Markings","text":"<p>NEAT's key innovation is historical markings — every gene (connection) receives a unique global ID when created:</p> <pre><code>Gene 1: Node A → Node B (innovation #1)\nGene 2: Node B → Node C (innovation #2)\nGene 3: Node A → Node C (innovation #3)  ← New connection\n</code></pre> <p>These markings enable meaningful crossover between networks with different topologies.</p>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#crossover-with-historical-genes","level":3,"title":"Crossover with Historical Genes","text":"<pre><code>flowchart TD\n    subgraph \"Parent 1\"\n        P1[\"Genes: 1, 2, 3, 4, 8\"]\n    end\n\n    subgraph \"Parent 2\"\n        P2[\"Genes: 1, 2, 3, 5, 6, 7\"]\n    end\n\n    subgraph \"Matching\"\n        M[\"1, 2, 3 — randomly inherit from either parent\"]\n    end\n\n    subgraph \"Disjoint/Excess\"\n        D[\"4, 5, 6, 7, 8 — inherit from fitter parent\"]\n    end\n\n    P1 --&gt; M\n    P2 --&gt; M\n    P1 --&gt; D\n    P2 --&gt; D\n    M --&gt; C[Child Genome]\n    D --&gt; C</code></pre>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#speciation","level":3,"title":"Speciation","text":"<p>NEAT protects innovation through speciation. New topological structures initially perform poorly but may lead to better solutions. By grouping similar genomes into species, NEAT prevents premature convergence.</p> <p>Species distance:</p> <pre><code>δ = c₁(E/N) + c₂(D/N) + c₃·W̄\n</code></pre> <p>Where: - E = excess genes - D = disjoint genes - W̄ = average weight difference - N = normalizing factor (genome size)</p>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#mutation-operators","level":3,"title":"Mutation Operators","text":"<pre><code>flowchart LR\n    subgraph \"Structural Mutations\"\n        A1[Add Node] --&gt; A2[\"Split existing connection\\nA→B becomes A→C→B\"]\n        B1[Add Connection] --&gt; B2[\"New edge between\\nexisting nodes\"]\n    end\n\n    subgraph \"Weight Mutations\"\n        C1[Perturb Weights] --&gt; C2[\"Small random changes\\nto connection weights\"]\n        D1[Reset Weight] --&gt; D2[\"Replace with new\\nrandom value\"]\n    end</code></pre>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#cppn-neat-for-morphology","level":2,"title":"CPPN-NEAT for Morphology","text":"<p>Combining CPPN and NEAT creates a powerful system for evolving creature bodies.</p>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#the-genotype-phenotype-mapping","level":3,"title":"The Genotype-Phenotype Mapping","text":"<pre><code>flowchart TD\n    subgraph Genotype\n        G[CPPN-NEAT Genome]\n        G --&gt; |Encodes| N[CPPN Network Topology]\n        G --&gt; |Encodes| W[Connection Weights]\n    end\n\n    subgraph Development\n        N --&gt; Q[Query at spatial coordinates]\n        W --&gt; Q\n        Q --&gt; O[Output values per location]\n    end\n\n    subgraph Phenotype\n        O --&gt; B[Body segments]\n        O --&gt; J[Joint placements]\n        O --&gt; M[Motor attachments]\n    end</code></pre>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#cppn-outputs-for-sunaba-creatures","level":3,"title":"CPPN Outputs for Sunaba Creatures","text":"Output Interpretation body_presence Whether material exists at this point (threshold) segment_id Which body segment this belongs to joint_type 0=none, 1=revolute, 2=prismatic, 3=fixed motor_strength Maximum torque for motorized joints limb_thickness Radius of body at this point","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#example-how-a-limb-emerges","level":3,"title":"Example: How a Limb Emerges","text":"<p>Consider a CPPN with a sine function in its hidden layer:</p> <ol> <li>Query points along the x-axis</li> <li>Sine function creates periodic output</li> <li>High values → body present</li> <li>Periodic high values → segmented limb</li> <li>Joint outputs between segments → articulated limb</li> </ol> <pre><code>flowchart LR\n    subgraph \"Query Points\"\n        P1[x=0] --&gt; V1[high]\n        P2[x=0.5] --&gt; V2[low]\n        P3[x=1.0] --&gt; V3[high]\n        P4[x=1.5] --&gt; V4[low]\n        P5[x=2.0] --&gt; V5[high]\n    end\n\n    subgraph \"Result\"\n        V1 --&gt; S1[Segment 1]\n        V3 --&gt; S2[Segment 2]\n        V5 --&gt; S3[Segment 3]\n        S1 ---|joint| S2\n        S2 ---|joint| S3\n    end</code></pre>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#in-sunaba","level":2,"title":"In Sunaba","text":"","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#joint-types","level":3,"title":"Joint Types","text":"<p>Sunaba creatures can have three joint types:</p> <p>Revolute — Rotation around a point (like an elbow) - 1 degree of freedom - Motor applies torque - Used for walking, swimming</p> <p>Prismatic — Linear sliding (like a piston) - 1 degree of freedom - Motor applies force - Used for jumping, striking</p> <p>Fixed — Rigid connection - 0 degrees of freedom - Structural support - Used for body cores</p>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#morphology-constraints","level":3,"title":"Morphology Constraints","text":"<p>To ensure physically viable creatures:</p> <ul> <li>Minimum body mass threshold</li> <li>Maximum aspect ratio</li> <li>Connectivity requirements (no floating parts)</li> <li>Joint limits to prevent self-intersection</li> </ul>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#evolved-morphology-examples","level":3,"title":"Evolved Morphology Examples","text":"<p>Evolution produces diverse body plans:</p> <ul> <li>Worm-like: Long chains of segments with revolute joints</li> <li>Spider-like: Central body with radiating limbs</li> <li>Blob-like: Compact bodies with few joints</li> <li>Snake-like: Undulating chains using prismatic joints</li> </ul>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#benefits-of-cppn-neat","level":2,"title":"Benefits of CPPN-NEAT","text":"<ol> <li>Indirect encoding — Small genomes produce complex bodies</li> <li>Geometric regularities — Natural symmetry and repetition</li> <li>Evolvability — Small mutations produce meaningful variations</li> <li>Open-ended — Topology can grow without bound</li> </ol>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"cppn-neat/#references","level":2,"title":"References","text":"<ul> <li>Stanley, K.O. (2007). \"Compositional Pattern Producing Networks: A Novel Abstraction of Development.\" Genetic Programming and Evolvable Machines.</li> <li>Stanley, K.O. &amp; Miikkulainen, R. (2002). \"Evolving Neural Networks through Augmenting Topologies.\" Evolutionary Computation.</li> <li>Cheney, N., MacCurdy, R., Clune, J., &amp; Lipson, H. (2013). \"Unshackling Evolution: Evolving Soft Robots with Multiple Materials and a Powerful Generative Encoding.\" GECCO.</li> <li>Clune, J., Stanley, K.O., Pennock, R.T., &amp; Ofria, C. (2011). \"On the Performance of Indirect Encoding Across the Continuum of Regularity.\" IEEE TEVC.</li> </ul>","path":["CPPN-NEAT: Procedural Morphology Generation"],"tags":[]},{"location":"emergent-physics/","level":1,"title":"Emergent Physics: Cellular Automata Foundations","text":"<p>Sunaba's world is built on cellular automata (CA) — a computational model where complex behaviors emerge from simple, local rules applied uniformly across a grid.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#a-brief-history-of-cellular-automata","level":2,"title":"A Brief History of Cellular Automata","text":"","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#von-neumann-and-self-replication-1940s","level":3,"title":"Von Neumann and Self-Replication (1940s)","text":"<p>John von Neumann, inspired by Stanislaw Ulam, developed the first cellular automaton to study self-replicating systems. His goal was to understand the logical requirements for a machine that could build copies of itself.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#conways-game-of-life-1970","level":3,"title":"Conway's Game of Life (1970)","text":"<p>John Conway's Game of Life demonstrated that four simple rules could produce extraordinary complexity:</p> <ol> <li>Any live cell with fewer than two neighbors dies (underpopulation)</li> <li>Any live cell with two or three neighbors survives</li> <li>Any live cell with more than three neighbors dies (overpopulation)</li> <li>Any dead cell with exactly three neighbors becomes alive (reproduction)</li> </ol> <p>From these rules emerge gliders, oscillators, and even Turing-complete computation.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#wolframs-elementary-automata-1983","level":3,"title":"Wolfram's Elementary Automata (1983)","text":"<p>Stephen Wolfram systematically studied one-dimensional CA, cataloging 256 possible rules. Rule 110 was proven Turing-complete, demonstrating that even the simplest CA can perform arbitrary computation.</p> <p>\"It is possible to construct a universal computer within any rule 110 system.\" — Matthew Cook, 2004</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#falling-sand-games-ca-for-material-simulation","level":2,"title":"Falling Sand Games: CA for Material Simulation","text":"<p>Falling sand games apply cellular automata principles to simulate physical materials. Each pixel has a material type, and update rules determine how materials interact.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#the-lineage","level":3,"title":"The Lineage","text":"<pre><code>timeline\n    title Evolution of Falling Sand Games\n    2005 : Falling Sand Game (Java applet)\n    2008 : Powder Game (Dan-Ball)\n    2009 : The Powder Toy\n    2019 : Noita\n    2026 : Sunaba</code></pre>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#why-falling-sand-works","level":3,"title":"Why Falling Sand Works","text":"<p>Traditional physics engines simulate rigid bodies with explicit collision detection. Falling sand takes a fundamentally different approach:</p> Aspect Rigid Body Physics Cellular Automata Unit Objects with shape/mass Individual pixels Interactions Collision detection Neighbor rules Complexity O(n²) pairwise checks O(n) local updates Emergence Limited High <p>The CA approach scales better and produces more emergent behaviors, at the cost of physical accuracy.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#sunabas-material-system","level":2,"title":"Sunaba's Material System","text":"","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#material-properties","level":3,"title":"Material Properties","text":"<p>Each material in Sunaba is defined by a set of properties:</p> <pre><code>Material: Water\n├── state: Liquid\n├── density: 1.0\n├── viscosity: 0.1\n├── thermal_conductivity: 0.6\n├── specific_heat: 4.18\n├── boiling_point: 100°C\n└── freezing_point: 0°C\n</code></pre> <p>Behaviors emerge from these properties, not from special-case code.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#visual-demonstrations","level":3,"title":"Visual Demonstrations","text":"","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#fire-propagation","level":4,"title":"Fire Propagation","text":"Fire spreading through wooden structures  <p>Fire spreads through flammable materials when temperature exceeds ignition point. No explicit \"fire spreading\" code exists — the behavior emerges from: - Wood's flammability property - Fire's heat output - Temperature diffusion - Material state transitions</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#liquid-physics","level":4,"title":"Liquid Physics","text":"Water flowing down platforms  <p>Liquids flow based on density, viscosity, and neighbor states. Water finds paths through gaps and pools at the lowest point through simple neighbor-checking rules.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#structural-dependencies","level":4,"title":"Structural Dependencies","text":"Bridge collapse cascade  <p>When a support pillar is removed, connected structures evaluate their support state. Unsupported sections convert to debris, triggering a cascade. This demonstrates emergent structural integrity from local connectivity checks.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#chemical-reactions","level":4,"title":"Chemical Reactions","text":"Lava and water reaction  <p>Lava + Water → Steam + Stone demonstrates temperature-based state changes. The reaction emerges from material properties and temperature thresholds, not hardcoded behavior.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#the-update-algorithm","level":3,"title":"The Update Algorithm","text":"<p>Sunaba processes pixels bottom-to-top, alternating horizontal direction each row to avoid directional bias:</p> <pre><code>flowchart TD\n    subgraph \"Frame Update\"\n        A[Start Frame] --&gt; B[Checkerboard Pass 1]\n        B --&gt; C[Checkerboard Pass 2]\n        C --&gt; D[Checkerboard Pass 3]\n        D --&gt; E[Checkerboard Pass 4]\n        E --&gt; F[End Frame]\n    end\n\n    subgraph \"Pixel Update\"\n        P1[Read Material Properties] --&gt; P2[Check Neighbors]\n        P2 --&gt; P3[Apply Movement Rules]\n        P3 --&gt; P4[Check Reactions]\n        P4 --&gt; P5[Update State]\n    end</code></pre> <p>The checkerboard pattern enables parallel chunk processing without race conditions.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#movement-rules-by-material-state","level":3,"title":"Movement Rules by Material State","text":"<p>Solids: - Stationary unless unsupported - Fall when no solid below - Stack on other solids</p> <p>Powders: - Fall straight down if empty - Slide diagonally if blocked below - Pile at angle of repose</p> <p>Liquids: - Fall if space below - Spread horizontally based on viscosity - Equalize pressure across connected regions</p> <p>Gases: - Rise based on density difference with air - Diffuse horizontally - Fill enclosed spaces</p> <pre><code>flowchart LR\n    subgraph \"Sand Movement Priority\"\n        direction TB\n        S1[Below] --&gt;|blocked| S2[Below-Left]\n        S2 --&gt;|blocked| S3[Below-Right]\n        S3 --&gt;|blocked| S4[Stay]\n    end\n\n    subgraph \"Water Movement Priority\"\n        direction TB\n        W1[Below] --&gt;|blocked| W2[Below-Left/Right]\n        W2 --&gt;|blocked| W3[Left/Right]\n        W3 --&gt;|blocked| W4[Stay]\n    end</code></pre>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#temperature-and-state-changes","level":2,"title":"Temperature and State Changes","text":"<p>Sunaba implements a coarse-grained temperature simulation layered on top of the CA:</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#temperature-grid","level":3,"title":"Temperature Grid","text":"<p>Temperature is simulated on an 8×8 supergrid for performance:</p> <pre><code>64×64 pixel chunk\n└── 8×8 temperature cells (8 pixels per cell)\n    └── Heat diffusion at 30 FPS\n</code></pre>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#state-transitions","level":3,"title":"State Transitions","text":"<p>Materials transition between states based on temperature:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; Ice: T &lt; 0°C\n    Ice --&gt; Water: T &gt; 0°C (melting)\n    Water --&gt; Ice: T &lt; 0°C (freezing)\n    Water --&gt; Steam: T &gt; 100°C (boiling)\n    Steam --&gt; Water: T &lt; 100°C (condensation)</code></pre>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#heat-diffusion","level":3,"title":"Heat Diffusion","text":"<p>Heat spreads according to the discrete heat equation:</p> <pre><code>T(t+1) = T(t) + k * Σ(T_neighbor - T) / neighbors\n</code></pre> <p>Where <code>k</code> is the thermal conductivity of the material.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#structural-integrity","level":2,"title":"Structural Integrity","text":"<p>When a solid structure loses its connection to anchored terrain, it must respond physically.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#the-flood-fill-algorithm","level":3,"title":"The Flood-Fill Algorithm","text":"<pre><code>flowchart TD\n    A[Pixel Removed] --&gt; B[Flood-fill connected solids]\n    B --&gt; C{Region anchored?}\n    C --&gt;|Yes| D[Structure stable]\n    C --&gt;|No| E{Region size?}\n    E --&gt;|Small &lt; 50px| F[Convert to particles]\n    E --&gt;|Large ≥ 50px| G[Convert to rigid body]</code></pre>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#debris-physics","level":3,"title":"Debris Physics","text":"<p>Large disconnected regions become rigid bodies simulated by Rapier2D physics engine. This creates dramatic collapses and falling debris.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#emergent-behaviors","level":2,"title":"Emergent Behaviors","text":"<p>None of these behaviors are explicitly programmed:</p> Behavior Emerges From Fire spreading Temperature + flammability Water erosion Liquid movement + solid displacement Cave-ins Structural integrity + gravity Steam geysers Heat + water + pressure Lava cooling Heat transfer + state change","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#noita-the-state-of-the-art","level":2,"title":"Noita: The State of the Art","text":"<p>Nolla Games' Noita (2019) represents the most sophisticated falling sand game to date. Their GDC 2019 talk revealed key techniques:</p> <ul> <li>Chunk-based parallel processing</li> <li>Material property matrices for reactions</li> <li>Rigid body integration for large debris</li> <li>GPU-accelerated rendering</li> </ul> <p>Sunaba builds on these foundations while adding ML-evolved creatures.</p>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"emergent-physics/#references","level":2,"title":"References","text":"<ul> <li>Wolfram, S. (2002). A New Kind of Science. Wolfram Media.</li> <li>Gardner, M. (1970). \"The Fantastic Combinations of John Conway's New Solitaire Game 'Life'.\" Scientific American.</li> <li>Cook, M. (2004). \"Universality in Elementary Cellular Automata.\" Complex Systems.</li> <li>Nolla Games. (2019). \"Exploring the Tech and Design of Noita.\" GDC Talk.</li> <li>The Powder Toy. (2009). Open-source falling sand game. https://powdertoy.co.uk/</li> </ul>","path":["Emergent Physics: Cellular Automata Foundations"],"tags":[]},{"location":"map-elites/","level":1,"title":"MAP-Elites: Quality-Diversity Optimization","text":"<p>Traditional evolutionary algorithms optimize a single fitness function, converging toward a single \"best\" solution. MAP-Elites takes a different approach: it simultaneously discovers diverse, high-quality solutions across a space of behavioral characteristics.</p>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#the-problem-with-fitness-only-optimization","level":2,"title":"The Problem with Fitness-Only Optimization","text":"","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#local-optima","level":3,"title":"Local Optima","text":"<p>Consider evolving creatures to move quickly. A fitness function rewarding speed will:</p> <ol> <li>Find an initial solution (e.g., rolling)</li> <li>Optimize that solution</li> <li>Get stuck if a different strategy (e.g., walking) requires passing through low-fitness intermediate forms</li> </ol> <pre><code>flowchart LR\n    subgraph \"Fitness Landscape\"\n        A[Rolling\\nLocal Optimum]\n        B[Valley\\nLow Fitness]\n        C[Walking\\nGlobal Optimum]\n    end\n    A -.-&gt;|\"Blocked by valley\"| B\n    B -.-&gt; C</code></pre>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#loss-of-diversity","level":3,"title":"Loss of Diversity","text":"<p>Fitness-only evolution exhibits premature convergence:</p> <ul> <li>Population concentrates around local optimum</li> <li>Genetic diversity collapses</li> <li>Exploration ceases</li> <li>Novel strategies become unreachable</li> </ul>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#quality-diversity-algorithms","level":2,"title":"Quality-Diversity Algorithms","text":"<p>Quality-Diversity (QD) algorithms reframe the goal:</p> <p>Instead of finding one optimal solution, find many solutions that are both high-quality and behaviorally diverse.</p>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#the-illumination-metaphor","level":3,"title":"The Illumination Metaphor","text":"<p>QD algorithms \"illuminate\" the space of possible behaviors, revealing which behaviors are achievable and how well they can be performed.</p> <pre><code>flowchart TD\n    subgraph \"Traditional EA\"\n        T1[Population] --&gt; T2[Single Optimum]\n    end\n\n    subgraph \"Quality-Diversity\"\n        Q1[Population] --&gt; Q2[Archive of Diverse Solutions]\n        Q2 --&gt; Q3[Full Behavior Space Coverage]\n    end</code></pre>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#the-map-elites-algorithm","level":2,"title":"The MAP-Elites Algorithm","text":"<p>MAP-Elites (Multi-dimensional Archive of Phenotypic Elites) maintains a grid of solutions, where each cell represents a region of behavior space.</p>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#algorithm-overview","level":3,"title":"Algorithm Overview","text":"<pre><code>flowchart TD\n    A[Initialize random solutions] --&gt; B[Evaluate each solution]\n    B --&gt; C[Compute behavior descriptor]\n    C --&gt; D[Find corresponding archive cell]\n    D --&gt; E{Cell empty OR new solution better?}\n    E --&gt;|Yes| F[Store in archive]\n    E --&gt;|No| G[Discard]\n    F --&gt; H[Select random solution from archive]\n    G --&gt; H\n    H --&gt; I[Mutate]\n    I --&gt; B</code></pre>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#key-components","level":3,"title":"Key Components","text":"<p>1. Behavior Descriptor (BD)</p> <p>A function mapping solutions to a low-dimensional behavior space:</p> <pre><code>BD: Solution → (b₁, b₂, ..., bₙ)\n</code></pre> <p>Example for creatures: - b₁ = proportion of time in contact with ground - b₂ = average height during movement</p> <p>2. Archive Grid</p> <p>The behavior space is discretized into a grid:</p> <pre><code>┌─────┬─────┬─────┬─────┐\n│     │  ●  │  ●  │     │  ● = Elite solution\n├─────┼─────┼─────┼─────┤\n│  ●  │  ●  │     │  ●  │\n├─────┼─────┼─────┼─────┤\n│     │  ●  │  ●  │  ●  │\n├─────┼─────┼─────┼─────┤\n│  ●  │     │  ●  │     │\n└─────┴─────┴─────┴─────┘\n       Behavior Dimension 1 →\n</code></pre> <p>3. Elite Replacement</p> <p>A new solution replaces the existing elite in its cell only if it has higher fitness.</p>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#pseudocode","level":3,"title":"Pseudocode","text":"<pre><code>Initialize archive A (empty grid)\nFor iteration = 1 to MAX_ITERATIONS:\n    If archive is empty:\n        x = random_solution()\n    Else:\n        x' = random_select(A)\n        x = mutate(x')\n\n    fitness = evaluate(x)\n    behavior = compute_behavior(x)\n    cell = discretize(behavior)\n\n    If A[cell] is empty OR fitness &gt; A[cell].fitness:\n        A[cell] = (x, fitness, behavior)\n</code></pre>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#behavior-dimensions-for-creatures","level":2,"title":"Behavior Dimensions for Creatures","text":"","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#locomotion-style","level":3,"title":"Locomotion Style","text":"<p>How does the creature move?</p> Dimension Low Value High Value Ground contact Aerial/jumping Crawling Body oscillation Rigid Undulating Limb usage Body-based Limb-based","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#diet-specialization","level":3,"title":"Diet Specialization","text":"<p>What does the creature eat?</p> Dimension Range Plant consumption 0% to 100% Meat consumption 0% to 100% Scavenging 0% to 100%","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#social-behavior","level":3,"title":"Social Behavior","text":"<p>How does the creature interact with others?</p> Dimension Low High Group size Solitary Swarm Cooperation Competitive Cooperative Territory Nomadic Territorial","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#strategy","level":3,"title":"Strategy","text":"<p>How does the creature behave under pressure?</p> Dimension Low High Aggression Evasive Aggressive Risk-taking Cautious Bold Resource hoarding Immediate consumption Stockpiling","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#why-qd-for-artificial-life","level":2,"title":"Why QD for Artificial Life?","text":"","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#1-ecological-niches-emerge-naturally","level":3,"title":"1. Ecological Niches Emerge Naturally","text":"<p>Different behavior regions correspond to different ecological niches:</p> <pre><code>flowchart TD\n    subgraph \"Behavior Space\"\n        A[Fast + Aggressive] --&gt; P[Predators]\n        B[Slow + Evasive] --&gt; H[Hiders]\n        C[Medium + Hoarding] --&gt; G[Gatherers]\n        D[Fast + Social] --&gt; S[Swarmers]\n    end</code></pre>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#2-robustness-through-diversity","level":3,"title":"2. Robustness Through Diversity","text":"<p>A diverse population is more robust to environmental changes. If conditions shift, some existing strategies may already be adapted.</p>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#3-stepping-stones-to-complex-behaviors","level":3,"title":"3. Stepping Stones to Complex Behaviors","text":"<p>Some behaviors are only reachable by passing through intermediate forms. MAP-Elites preserves these stepping stones.</p> <pre><code>flowchart LR\n    A[Simple Rolling] --&gt; B[Rolling + Steering]\n    B --&gt; C[Steering + Limb Growth]\n    C --&gt; D[Walking]\n\n    style A fill:#f9f\n    style B fill:#f9f\n    style C fill:#f9f\n    style D fill:#9f9</code></pre>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#4-co-evolution-dynamics","level":3,"title":"4. Co-evolution Dynamics","text":"<p>When multiple species co-evolve, diversity prevents arms races from collapsing to single strategies.</p>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#in-sunaba","level":2,"title":"In Sunaba","text":"","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#behavior-characterization-functions","level":3,"title":"Behavior Characterization Functions","text":"<p>Sunaba computes behavior descriptors from creature performance:</p> <pre><code>Locomotion BC:\n- ground_contact_ratio: time touching ground / total time\n- average_height: mean y-position during evaluation\n- distance_traveled: total displacement\n- movement_efficiency: distance / energy_spent\n\nForaging BC:\n- food_types_eaten: count of distinct materials consumed\n- foraging_range: area covered while seeking food\n- consumption_rate: food eaten / time\n</code></pre>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#archive-visualization","level":3,"title":"Archive Visualization","text":"<p>The MAP-Elites archive can be visualized as a heatmap:</p> <pre><code>          Ground Contact →\n        0.0   0.25  0.5   0.75  1.0\n      ┌─────┬─────┬─────┬─────┬─────┐\n H  0 │ 0.2 │ 0.4 │     │     │     │\n e    ├─────┼─────┼─────┼─────┼─────┤\n i  1 │ 0.3 │ 0.7 │ 0.8 │ 0.5 │     │\n g    ├─────┼─────┼─────┼─────┼─────┤\n h  2 │     │ 0.6 │ 0.9 │ 0.8 │ 0.6 │\n t    ├─────┼─────┼─────┼─────┼─────┤\n ↓  3 │     │     │ 0.7 │ 0.9 │ 0.7 │\n      └─────┴─────┴─────┴─────┴─────┘\n\n      Cell values = fitness scores\n</code></pre>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#multi-archive-evolution","level":3,"title":"Multi-Archive Evolution","text":"<p>Sunaba supports multiple archives for different fitness objectives:</p> <ul> <li>Locomotion archive (speed, efficiency)</li> <li>Foraging archive (resource gathering)</li> <li>Combat archive (hunting success)</li> <li>Survival archive (longevity)</li> </ul> <p>Creatures can be sampled from any archive for different purposes.</p>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#comparison-with-other-algorithms","level":2,"title":"Comparison with Other Algorithms","text":"Algorithm Diversity Quality Scalability Standard EA Low High High Novelty Search High Variable Medium NSGA-II Medium High Medium MAP-Elites High High High","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#advanced-topics","level":2,"title":"Advanced Topics","text":"","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#cvt-map-elites","level":3,"title":"CVT-MAP-Elites","text":"<p>Centroidal Voronoi Tessellation (CVT) replaces the regular grid with adaptive cells that better cover the behavior space.</p>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#deep-grid","level":3,"title":"Deep Grid","text":"<p>Hierarchical grids that allocate finer resolution to dense regions.</p>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#map-elites-with-curiosity","level":3,"title":"MAP-Elites with Curiosity","text":"<p>Bonus rewards for discovering new cells, encouraging exploration of unoccupied regions.</p>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"map-elites/#references","level":2,"title":"References","text":"<ul> <li>Mouret, J.-B. &amp; Clune, J. (2015). \"Illuminating search spaces by mapping elites.\" arXiv preprint arXiv:1504.04909.</li> <li>Pugh, J.K., Soros, L.B., &amp; Stanley, K.O. (2016). \"Quality Diversity: A New Frontier for Evolutionary Computation.\" Frontiers in Robotics and AI.</li> <li>Cully, A., Clune, J., Tarapore, D., &amp; Mouret, J.-B. (2015). \"Robots that can adapt like animals.\" Nature.</li> <li>Lehman, J. &amp; Stanley, K.O. (2011). \"Abandoning Objectives: Evolution Through the Search for Novelty Alone.\" Evolutionary Computation.</li> <li>Vassiliades, V., Chatzilygeroudis, K., &amp; Mouret, J.-B. (2017). \"Using Centroidal Voronoi Tessellations to Scale Up the Multidimensional Archive of Phenotypic Elites Algorithm.\" IEEE TEVC.</li> </ul>","path":["MAP-Elites: Quality-Diversity Optimization"],"tags":[]},{"location":"neural-control/","level":1,"title":"Neural Control: Brain Architectures for Embodied Agents","text":"<p>Creatures in Sunaba need brains that can control their evolved bodies. This presents a unique challenge: the neural controller must work with any morphology that CPPN-NEAT produces.</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#the-embodied-cognition-challenge","level":2,"title":"The Embodied Cognition Challenge","text":"","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#variable-morphology","level":3,"title":"Variable Morphology","text":"<p>Unlike traditional robotics where the body is fixed, evolved creatures have: - Variable numbers of limbs - Different joint configurations - Varying sensor placements - Diverse body proportions</p> <p>A fixed-architecture neural network cannot handle this variability.</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#sensorimotor-coordination","level":3,"title":"Sensorimotor Coordination","text":"<p>The brain must: 1. Sense — Receive inputs from proprioceptive and exteroceptive sensors 2. Process — Integrate information into a coherent world model 3. Act — Generate coordinated motor commands</p> <pre><code>flowchart LR\n    subgraph Sensors\n        P[Proprioception]\n        E[Exteroception]\n    end\n\n    subgraph Brain\n        I[Integration]\n        D[Decision]\n    end\n\n    subgraph Motors\n        M[Motor Commands]\n    end\n\n    P --&gt; I\n    E --&gt; I\n    I --&gt; D\n    D --&gt; M</code></pre>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#graph-neural-networks-for-morphology","level":2,"title":"Graph Neural Networks for Morphology","text":"","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#the-key-insight","level":3,"title":"The Key Insight","text":"<p>A creature's body can be represented as a graph: - Nodes = Body segments - Edges = Joints connecting segments</p> <p>Graph Neural Networks (GNNs) naturally process graph-structured data, making them ideal for morphology-aware control.</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#nervenet-architecture","level":3,"title":"NerveNet Architecture","text":"<p>NerveNet (Wang et al., 2018) pioneered GNN-based control for articulated bodies:</p> <pre><code>flowchart TD\n    subgraph \"Body Graph\"\n        A[Torso] --- B[Left Arm]\n        A --- C[Right Arm]\n        A --- D[Left Leg]\n        A --- E[Right Leg]\n    end\n\n    subgraph \"Message Passing\"\n        B --&gt; |\"message\"| A\n        C --&gt; |\"message\"| A\n        D --&gt; |\"message\"| A\n        E --&gt; |\"message\"| A\n        A --&gt; |\"message\"| B\n        A --&gt; |\"message\"| C\n        A --&gt; |\"message\"| D\n        A --&gt; |\"message\"| E\n    end</code></pre>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#message-passing","level":3,"title":"Message Passing","text":"<p>Each node computes messages to send to neighbors based on: - Its own state (joint angles, velocities) - The edge properties (joint type, limits)</p> <pre><code>m_ij = MLP_message(h_i, h_j, e_ij)\n</code></pre> <p>Nodes aggregate incoming messages:</p> <pre><code>h_i' = MLP_update(h_i, Σ_j m_ji)\n</code></pre> <p>After several message-passing rounds, each node has information about the global body state.</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#benefits-of-gnn-control","level":3,"title":"Benefits of GNN Control","text":"Property Benefit Variable input size Handles any number of limbs Local computation Scales linearly with body size Permutation equivariance Robust to limb ordering Transfer learning Policies can transfer between bodies","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#transformer-architectures","level":2,"title":"Transformer Architectures","text":"","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#amorpheus","level":3,"title":"AMORPHEUS","text":"<p>AMORPHEUS (Gupta et al., 2021) applies transformer attention to morphology control:</p> <pre><code>flowchart TD\n    subgraph \"Self-Attention\"\n        A[Torso Token]\n        B[Arm 1 Token]\n        C[Arm 2 Token]\n        D[Leg 1 Token]\n        E[Leg 2 Token]\n\n        A &lt;--&gt; B\n        A &lt;--&gt; C\n        A &lt;--&gt; D\n        A &lt;--&gt; E\n        B &lt;--&gt; C\n        D &lt;--&gt; E\n    end</code></pre>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#attention-mechanism","level":3,"title":"Attention Mechanism","text":"<p>Each body part attends to all other parts:</p> <pre><code>Attention(Q, K, V) = softmax(QK^T / √d) V\n</code></pre> <p>Where Q, K, V are projections of segment states.</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#positional-encoding-for-bodies","level":3,"title":"Positional Encoding for Bodies","text":"<p>Unlike sequences, bodies have graph structure. AMORPHEUS uses: - Proprioceptive encoding — Joint angles and velocities - Morphological encoding — Body part type, parent relationship - Spatial encoding — Position relative to body center</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#sensor-systems","level":2,"title":"Sensor Systems","text":"","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#proprioception","level":3,"title":"Proprioception","text":"<p>Internal body sensing:</p> Sensor Information Joint angle Current position of each joint Joint velocity Rate of change of joint angle Joint torque Force being applied by motor Contact Binary: is this part touching something?","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#exteroception","level":3,"title":"Exteroception","text":"<p>External world sensing:</p> <pre><code>flowchart LR\n    subgraph \"Raycast Sensors\"\n        R1[Forward ray]\n        R2[Downward ray]\n        R3[Lateral rays]\n    end\n\n    subgraph \"Returns\"\n        D[Distance to hit]\n        M[Material type]\n        T[Temperature]\n    end\n\n    R1 --&gt; D\n    R1 --&gt; M\n    R1 --&gt; T</code></pre> Sensor Information Raycasts Distance/material in various directions Ground detection What's beneath each foot Food detection Nearby edible materials Threat detection Nearby predators/dangers","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#sensor-brain-pipeline","level":3,"title":"Sensor-Brain Pipeline","text":"<pre><code>flowchart TD\n    subgraph \"Raw Sensors\"\n        P[Proprioception: 4 values per joint]\n        E[Exteroception: 8 raycasts × 3 values]\n    end\n\n    subgraph \"Encoding\"\n        PE[Proprioceptive Encoder]\n        EE[Exteroceptive Encoder]\n    end\n\n    subgraph \"Brain\"\n        F[Feature Integration]\n        H[Hidden Layers]\n        O[Output Layer]\n    end\n\n    subgraph \"Motors\"\n        M[Motor Commands: 1 per actuated joint]\n    end\n\n    P --&gt; PE\n    E --&gt; EE\n    PE --&gt; F\n    EE --&gt; F\n    F --&gt; H\n    H --&gt; O\n    O --&gt; M</code></pre>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#co-evolution-of-body-and-brain","level":2,"title":"Co-evolution of Body and Brain","text":"","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#why-they-must-evolve-together","level":3,"title":"Why They Must Evolve Together","text":"<p>Bodies and brains are deeply coupled: - A body optimized for a different brain won't function - A brain optimized for a different body won't control well</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#developmental-coupling","level":3,"title":"Developmental Coupling","text":"<p>In nature, bodies and nervous systems develop together. Nerves grow along with limbs. Sunaba mimics this:</p> <ol> <li>CPPN-NEAT generates morphology</li> <li>Body graph determines neural architecture</li> <li>Neural weights are part of the genome</li> <li>Both evolve together under selection</li> </ol>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#the-baldwin-effect","level":3,"title":"The Baldwin Effect","text":"<p>An interesting phenomenon emerges:</p> <ol> <li>Learning (neural adaptation) helps individuals survive</li> <li>Individuals with better learning capacity are selected</li> <li>Eventually, learned behaviors become \"hardcoded\"</li> </ol> <p>This accelerates evolution by allowing beneficial behaviors to be discovered through learning before being genetically encoded.</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#in-sunaba","level":2,"title":"In Sunaba","text":"","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#deep-neural-controller","level":3,"title":"Deep Neural Controller","text":"<p>Sunaba uses a deep feedforward network with the following structure:</p> <pre><code>flowchart TD\n    subgraph \"Input Layer\"\n        I1[Proprioceptive inputs]\n        I2[Exteroceptive inputs]\n        I3[Internal state hunger/health]\n    end\n\n    subgraph \"Hidden Layers\"\n        H1[Dense Layer 64 units]\n        H2[Dense Layer 64 units]\n        H3[Dense Layer 32 units]\n    end\n\n    subgraph \"Output Layer\"\n        O[Motor commands per joint]\n    end\n\n    I1 --&gt; H1\n    I2 --&gt; H1\n    I3 --&gt; H1\n    H1 --&gt; H2\n    H2 --&gt; H3\n    H3 --&gt; O</code></pre>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#input-encoding","level":3,"title":"Input Encoding","text":"<p>For each joint: - Angle (normalized to [-1, 1]) - Angular velocity (normalized) - Motor activation (previous frame)</p> <p>Global inputs: - Health level - Hunger level - Orientation (sin/cos of body angle)</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#output-decoding","level":3,"title":"Output Decoding","text":"<p>Each output corresponds to a motor: - Range: [-1, 1] - -1 = maximum torque in negative direction - 0 = no torque - +1 = maximum torque in positive direction</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#activation-functions","level":3,"title":"Activation Functions","text":"<ul> <li>Hidden layers: ReLU (fast, avoids vanishing gradients)</li> <li>Output layer: Tanh (bounded motor commands)</li> </ul>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#weight-initialization","level":3,"title":"Weight Initialization","text":"<p>Weights are initialized using He initialization and then evolved. Initial random weights produce random behaviors, which MAP-Elites explores.</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#performance-considerations","level":2,"title":"Performance Considerations","text":"","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#inference-speed","level":3,"title":"Inference Speed","text":"<p>With many creatures, neural inference becomes a bottleneck:</p> Optimization Impact SIMD operations 2-4x speedup Batch inference Reduces per-creature overhead Pruned networks Smaller networks run faster Fixed-point Reduces memory bandwidth","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#neural-stepping-frequency","level":3,"title":"Neural Stepping Frequency","text":"<p>Brains don't need to run every physics frame: - Physics: 60 FPS - Neural: 15-30 FPS (configurable) - Motor commands interpolated between decisions</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#future-directions","level":2,"title":"Future Directions","text":"","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#hierarchical-control","level":3,"title":"Hierarchical Control","text":"<p>Separating high-level goals from low-level motor control:</p> <pre><code>flowchart TD\n    G[Goal Selection: GOAP] --&gt; T[Task Planning]\n    T --&gt; S[Skill Selection]\n    S --&gt; M[Motor Control: Neural]\n    M --&gt; A[Actions]</code></pre>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#memory-and-attention","level":3,"title":"Memory and Attention","text":"<p>Adding recurrent or transformer layers for: - Remembering past observations - Tracking moving prey/threats - Planning multi-step sequences</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#meta-learning","level":3,"title":"Meta-Learning","text":"<p>Training controllers that can quickly adapt to new bodies, enabling faster evolution of novel morphologies.</p>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"neural-control/#references","level":2,"title":"References","text":"<ul> <li>Wang, T., Liao, R., Ba, J., &amp; Fidler, S. (2018). \"NerveNet: Learning Structured Policy with Graph Neural Networks.\" ICLR.</li> <li>Huang, W., Mordatch, I., &amp; Pathak, D. (2020). \"One Policy to Control Them All: Shared Modular Policies for Agent-Agnostic Control.\" ICML.</li> <li>Gupta, A., Fan, L., Ganguli, S., &amp; Fei-Fei, L. (2021). \"MetaMorph: Learning Universal Controllers with Transformers.\" ICLR.</li> <li>Ha, D. (2019). \"Reinforcement Learning for Improving Agent Design.\" Artificial Life.</li> <li>Heess, N., et al. (2017). \"Emergence of Locomotion Behaviours in Rich Environments.\" arXiv.</li> </ul>","path":["Neural Control: Brain Architectures for Embodied Agents"],"tags":[]},{"location":"prior-work/","level":1,"title":"Prior Work: Literature Review and Inspirations","text":"<p>Sunaba builds on decades of research across multiple fields. This page surveys the key works and ideas that inform the project.</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#artificial-life-a-brief-history","level":2,"title":"Artificial Life: A Brief History","text":"<pre><code>timeline\n    title Evolution of Artificial Life Research\n    1940s : Von Neumann's self-replicating automata\n    1970 : Conway's Game of Life\n    1987 : First Artificial Life conference\n    1990 : Tierra - digital evolution\n    1994 : Karl Sims' Evolved Virtual Creatures\n    2002 : NEAT - neuroevolution\n    2007 : CPPN - indirect encoding\n    2015 : MAP-Elites - quality-diversity\n    2019 : Noita - falling sand physics</code></pre>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#von-neumanns-self-replicating-automata-1940s","level":3,"title":"Von Neumann's Self-Replicating Automata (1940s)","text":"<p>John von Neumann asked: what are the logical requirements for a machine to reproduce itself? His cellular automaton model proved that self-replication was possible in a computational system, laying the groundwork for all artificial life research.</p> <p>\"The question is whether it is possible to formulate the definition of life in a way that is both precise and inclusive.\" — John von Neumann</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#tierra-1990","level":3,"title":"Tierra (1990)","text":"<p>Thomas Ray created Tierra, a virtual world where self-replicating computer programs competed for CPU time and memory. Amazingly, evolution produced: - Parasites (programs that hijack others' reproduction) - Hyper-parasites (programs that exploit parasites) - Social organisms (programs that cooperate)</p> <p>No human designed these strategies—they emerged from evolutionary pressure.</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#karl-sims-evolved-virtual-creatures-1994","level":3,"title":"Karl Sims' Evolved Virtual Creatures (1994)","text":"<p>Karl Sims' seminal work demonstrated that complex, lifelike creatures could emerge from evolution:</p> <ul> <li>Directed graphs encoded creature morphology</li> <li>Neural networks controlled behavior</li> <li>Bodies and brains evolved together</li> <li>Creatures competed in virtual environments</li> </ul> <p>The resulting creatures exhibited: - Swimming behaviors - Walking and running - Following light sources - Fighting over resources</p> <p>This work directly inspired Sunaba's approach to creature evolution.</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#paper","level":3,"title":"Paper","text":"<p>Sims, K. (1994). \"Evolving Virtual Creatures.\" SIGGRAPH '94 Proceedings.</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#falling-sand-games","level":2,"title":"Falling Sand Games","text":"","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#origins","level":3,"title":"Origins","text":"<p>The falling sand genre emerged from early experiments with pixel-based physics:</p> <p>Falling Sand Game (2005) - Java applet - Basic materials: sand, water, plant - First viral falling sand game</p> <p>The Powder Toy (2009) - Open source - Hundreds of materials - Complex reactions (nuclear, electrical) - Still actively developed</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#noita-2019","level":3,"title":"Noita (2019)","text":"<p>Nolla Games' Noita represents the pinnacle of falling sand gaming:</p> <p>Technical Achievements: - Every pixel physically simulated - Material reactions via lookup tables - Parallel chunk processing - Rigid body physics integration - GPU-accelerated rendering</p> <p>Game Design: - Roguelike structure - Magic wand crafting - Physics-based puzzles - Emergent combat strategies</p> <p>Noita's GDC talk (2019) revealed many techniques Sunaba adopts: - Checkerboard update patterns - Temperature simulation - Structural integrity systems - Debris conversion to rigid bodies</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#neuroevolution","level":2,"title":"Neuroevolution","text":"","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#neat-2002","level":3,"title":"NEAT (2002)","text":"<p>Stanley and Miikkulainen's NEAT (NeuroEvolution of Augmenting Topologies) solved the challenge of evolving neural network structure:</p> <p>Key Innovations: 1. Historical markings enable crossover between different topologies 2. Speciation protects new innovations 3. Complexification from minimal structures</p> <p>NEAT showed that evolving topology and weights together outperformed fixed-topology approaches.</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#hyperneat-2007","level":3,"title":"HyperNEAT (2007)","text":"<p>HyperNEAT extended NEAT using CPPNs as an indirect encoding: - CPPN outputs connection weights - Allows geometric regularities in weight patterns - Scales to large networks</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#es-hyperneat-2012","level":3,"title":"ES-HyperNEAT (2012)","text":"<p>Evolution Strategies combined with HyperNEAT: - CPPNs determine which connections exist - Enables sparse, adaptive connectivity - Better scaling to complex problems</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#quality-diversity-evolution","level":2,"title":"Quality-Diversity Evolution","text":"","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#novelty-search-2011","level":3,"title":"Novelty Search (2011)","text":"<p>Lehman and Stanley's Novelty Search abandoned fitness entirely: - Only reward behavioral novelty - Avoids deceptive fitness landscapes - Discovers stepping stones to complex behaviors</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#map-elites-2015","level":3,"title":"MAP-Elites (2015)","text":"<p>Mouret and Clune's MAP-Elites combined novelty and fitness: - Maintain archive of diverse solutions - Each solution is elite for its behavioral niche - Illuminates the space of possible behaviors</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#applications-to-robotics","level":3,"title":"Applications to Robotics","text":"<p>Cully et al. (2015) used MAP-Elites for robot damage recovery: - Pre-compute archive of walking behaviors - When damaged, robot searches archive for working alternatives - Recovery in under 2 minutes</p> <p>This demonstrated QD's practical value for adaptive systems.</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#soft-body-evolution","level":2,"title":"Soft Body Evolution","text":"","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#the-golem-project-2000","level":3,"title":"The Golem Project (2000)","text":"<p>Lipson and Pollack automatically designed and fabricated robots: - Simulated evolution of body and brain - Physical robots built from evolved designs - Demonstrated simulation-to-reality transfer</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#voxel-based-soft-robots","level":3,"title":"Voxel-Based Soft Robots","text":"<p>Recent work evolves soft robots from voxel grids:</p> <p>Cheney et al. (2013) - Evolved soft robots with multiple materials - CPPN-generated morphologies - Demonstrated complex locomotion</p> <p>Kriegman et al. (2020) — Xenobots - Evolved cell configurations - Built from biological cells - First living robots</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#multi-agent-evolution","level":2,"title":"Multi-Agent Evolution","text":"","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#competitive-co-evolution","level":3,"title":"Competitive Co-evolution","text":"<p>When agents evolve against each other:</p> <pre><code>flowchart LR\n    P[Predators] &lt;--&gt;|\"co-evolve\"| Y[Prey]\n    Y --&gt;|\"select for\"| F[Faster prey]\n    P --&gt;|\"select for\"| S[Smarter predators]\n    F --&gt;|\"select for\"| P\n    S --&gt;|\"select for\"| Y</code></pre> <p>Advantages: - Open-ended complexity growth - No fixed fitness function needed - Arms races drive innovation</p> <p>Challenges: - Red Queen dynamics (running to stay in place) - Loss of gradient (cycling behaviors) - Forgetting old strategies</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#poet-2019","level":3,"title":"POET (2019)","text":"<p>Wang et al.'s POET (Paired Open-Ended Trailblazer) co-evolves environments and agents: - Environments become harder as agents improve - Agents transfer between environments - Produces generalist agents</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#intrinsic-motivation","level":3,"title":"Intrinsic Motivation","text":"<p>Modern systems add internal drives: - Curiosity (seek novel states) - Empowerment (maximize influence on environment) - Skill learning (acquire reusable behaviors)</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#physics-simulation","level":2,"title":"Physics Simulation","text":"","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#rapier2d","level":3,"title":"Rapier2D","text":"<p>Sunaba uses Rapier for rigid body physics: - Written in Rust - Deterministic simulation - Supports joints and motors - Cross-platform (including WASM)</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#physics-based-character-animation","level":3,"title":"Physics-Based Character Animation","text":"<p>The computer graphics community has developed techniques for physically simulated characters:</p> <p>DeepMimic (2018) - Neural networks learn from motion capture - Physically simulated execution - Robust to perturbations</p> <p>Character Controllers (Peng et al.) - Hierarchical policies - Reusable skills library - Transfer to new morphologies</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#behavioral-ai","level":2,"title":"Behavioral AI","text":"","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#goap-goal-oriented-action-planning","level":3,"title":"GOAP (Goal-Oriented Action Planning)","text":"<p>GOAP separates what to do from how to do it:</p> <pre><code>flowchart TD\n    G[Goal: Be Fed] --&gt; P[Planner]\n    P --&gt; A1[Find Food]\n    A1 --&gt; A2[Move to Food]\n    A2 --&gt; A3[Eat Food]\n\n    subgraph \"World State\"\n        W[has_food: false]\n    end</code></pre> <p>Originally developed for F.E.A.R. (2005), GOAP enables: - Emergent behavior sequences - Dynamic replanning - Readable AI logic</p> <p>Sunaba plans to use GOAP for high-level creature decisions.</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#behavior-trees","level":3,"title":"Behavior Trees","text":"<p>An alternative to GOAP, behavior trees provide: - Hierarchical behavior organization - Priority-based selection - Reactive responses</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#key-papers","level":2,"title":"Key Papers","text":"","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#foundational","level":3,"title":"Foundational","text":"<ul> <li>Von Neumann, J. (1966). Theory of Self-Reproducing Automata. Ed. Arthur W. Burks.</li> <li>Wolfram, S. (2002). A New Kind of Science.</li> <li>Ray, T. (1991). \"An Approach to the Synthesis of Life.\" Artificial Life II.</li> </ul>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#evolution","level":3,"title":"Evolution","text":"<ul> <li>Stanley, K.O. &amp; Miikkulainen, R. (2002). \"Evolving Neural Networks through Augmenting Topologies.\" Evolutionary Computation.</li> <li>Stanley, K.O. (2007). \"Compositional Pattern Producing Networks.\" Genetic Programming and Evolvable Machines.</li> <li>Mouret, J.-B. &amp; Clune, J. (2015). \"Illuminating search spaces by mapping elites.\" arXiv:1504.04909.</li> </ul>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#creatures","level":3,"title":"Creatures","text":"<ul> <li>Sims, K. (1994). \"Evolving Virtual Creatures.\" SIGGRAPH '94.</li> <li>Cheney, N., MacCurdy, R., Clune, J., &amp; Lipson, H. (2013). \"Unshackling Evolution.\" GECCO '13.</li> <li>Wang, T., Liao, R., Ba, J., &amp; Fidler, S. (2018). \"NerveNet.\" ICLR 2018.</li> </ul>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#games","level":3,"title":"Games","text":"<ul> <li>Nolla Games. (2019). \"Exploring the Tech and Design of Noita.\" GDC.</li> <li>Orkin, J. (2006). \"Three States and a Plan: The A.I. of F.E.A.R.\" GDC.</li> </ul>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]},{"location":"prior-work/#recommended-reading","level":2,"title":"Recommended Reading","text":"<p>For those wanting to dive deeper:</p> <p>Books: - Floreano, D. &amp; Mattiussi, C. (2008). Bio-Inspired Artificial Intelligence. MIT Press. - Stanley, K.O. &amp; Lehman, J. (2015). Why Greatness Cannot Be Planned. Springer. - Mitchell, M. (2009). Complexity: A Guided Tour. Oxford UP.</p> <p>Survey Papers: - Pugh, J.K., Soros, L.B., &amp; Stanley, K.O. (2016). \"Quality Diversity: A New Frontier.\" Frontiers in Robotics and AI. - Doncieux, S., Bredeche, N., Mouret, J.-B., &amp; Eiben, A.E. (2015). \"Evolutionary Robotics: What, Why, and Where to.\" Frontiers in Robotics and AI. - Stanley, K.O., Clune, J., Lehman, J., &amp; Miikkulainen, R. (2019). \"Designing Neural Networks through Neuroevolution.\" Nature Machine Intelligence.</p> <p>Video: - Karl Sims' \"Evolved Virtual Creatures\" (1994) — YouTube - Noita GDC Talk (2019) — GDC Vault - NEAT Explained — Various YouTube tutorials</p>","path":["Prior Work: Literature Review and Inspirations"],"tags":[]}]}